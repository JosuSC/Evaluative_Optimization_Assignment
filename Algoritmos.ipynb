{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c594bf91",
   "metadata": {},
   "source": [
    "# Algoritmos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cf11b",
   "metadata": {},
   "source": [
    "### En este notebook Jupyter veremos los algoritmos que utilizamos para resolver nuestro problema:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997d89e",
   "metadata": {},
   "source": [
    "- Máximo Descendiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af434a4",
   "metadata": {},
   "source": [
    "- Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134cf107",
   "metadata": {},
   "source": [
    "### A continuación pasamos a la explicación de cada uno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fcb027",
   "metadata": {},
   "source": [
    "# Descenso por Gradiente (Gradientes descendentes):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815c0f6",
   "metadata": {},
   "source": [
    "### 1) Encabezado y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b821d",
   "metadata": {},
   "source": [
    "Qué hace: importa numpy para cálculo numérico (vectores, operaciones, funciones trigonométricas) y\n",
    "matplotlib.pyplot para graficar.\n",
    "\n",
    "Breve teoría: numpy permite trabajar con arrays y operaciones vectoriales de forma eficiente; usarlo evita\n",
    "bucles innecesarios y errores de precisión cuando se evalúa la función en mallas para las curvas de nivel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d54d2",
   "metadata": {},
   "source": [
    "### 2) Definición de la función objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205387ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return 1 / (2 + np.cos(x + y)) + ((x- y)**2 + (x + y)**2) / 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cf1c1",
   "metadata": {},
   "source": [
    "Qué hace: devuelve el valor de la función f(x,y) que vamos a minimizar.\n",
    "\n",
    "Breve teoría: la función tiene dos componentes: 1/(2 + cos(x + y)) (término oscilatorio y acotado) y un\n",
    "término cuadrático ((x−y)**2 + (x+y)**2)/20\n",
    "que aporta coercividad (crece con la norma ∥(x,y)∥), lo cual favorece la\n",
    "existencia de mínimos globales y proporciona curvatura para el descenso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909f69e",
   "metadata": {},
   "source": [
    "### 3) Gradiente analítico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x, y):\n",
    "    df_dx = np.sin(x + y) / (2 + np.cos(x + y))**2 + x / 5\n",
    "    df_dy = np.sin(x + y) / (2 + np.cos(x + y))**2 + y / 5\n",
    "    return np.array([df_dx, df_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1d524",
   "metadata": {},
   "source": [
    "Qué hace: calcula las derivadas parciales ∂f/∂x y ∂f/∂y y las empaqueta en un vector.\n",
    "\n",
    "Breve teoría: el gradiente indica la dirección de mayor aumento de f; para minimizar usamos la dirección\n",
    "opuesta (−∇f). Es preferible emplear derivadas analíticas por precisión y velocidad frente a diferencias finitas.\n",
    "Observa que la parte trigonométrica aporta el término sin(x + y)/(2 + cos(x + y))**2 en ambas componentes,\n",
    "y la parte cuadrática da x/5 y y/5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ce789",
   "metadata": {},
   "source": [
    "### 4) Parámetros del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "eps = 1e-6\n",
    "max_iter = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fa020",
   "metadata": {},
   "source": [
    "Qué hace: fija el tamaño de paso constante α, la tolerancia para parada y el número máximo de iteraciones.\n",
    "\n",
    "Breve teoría: α condiciona estabilidad y rapidez: pasos grandes aceleran pero pueden causar divergencia;\n",
    "pasos pequeños aseguran estabilidad pero hacen lenta la convergencia. ε controla la precisión del criterio de\n",
    "parada (a menor ε, mayor precisión y más iteraciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64b55f",
   "metadata": {},
   "source": [
    "### 5) Puntos iniciales y estructura de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_iniciales = [np.array([2,-10]), np.array([-50, 5]), np.array([26,-10])]\n",
    "resultados_grad = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11909d",
   "metadata": {},
   "source": [
    "Qué hace: define varios inicios para probar la robustez del método y prepara la lista donde se guardarán\n",
    "resultados.\n",
    "\n",
    "Breve teoría: para funciones no convexas o con oscilaciones locales, distintos puntos iniciales pueden\n",
    "converger a distintos mínimos locales; probar varios inicios ayuda a detectar sensibilidad y a evaluar si el\n",
    "mínimo encontrado es global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ede072",
   "metadata": {},
   "source": [
    "### 6) Bucle principal — inicialización por punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x0 in puntos_iniciales:\n",
    "    x = x0.copy()\n",
    "    trayectoria = [x.copy()]\n",
    "for i in range(max_iter):\n",
    "    g = grad_f(x[0], x[1])\n",
    "    x_new = x- alpha * g\n",
    "    trayectoria.append(x_new.copy())\n",
    "    if np.linalg.norm(x_new- x) < eps:\n",
    "        break\n",
    "    x = x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ffe00",
   "metadata": {},
   "source": [
    "Qué hace: para cada punto inicial ejecuta el proceso iterativo del gradiente descendente:\n",
    "1. calcula el gradiente g = ∇f(x),\n",
    "2. actualiza x_nuevo = x − αg,\n",
    "3. guarda la trayectoria,\n",
    "4. comprueba si el cambio es menor que ε y, si es así, para.\n",
    "\n",
    "Breve teoría: el criterio de parada usado es la norma del paso ∥x_{k+1}−x_k∥. Alternativamente se puede usar\n",
    "∥∇f(x)∥ (norma del gradiente) para detectar cercanía a un punto crítico. Guardar la trayectoria permite\n",
    "analizar comportamiento (oscilaciones, convergencia lenta/rápida)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8a2e1",
   "metadata": {},
   "source": [
    "###  7) Almacenamiento del resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_grad.append({\n",
    "\"inicio\": x0,\n",
    "\"minimo\": x,\n",
    "\"valor_minimo\": f(x[0], x[1]),\n",
    "\"iteraciones\": i+1,\n",
    "\"trayectoria\": np.array(trayectoria)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc87a0",
   "metadata": {},
   "source": [
    "Qué hace: guarda, para cada inicial, el punto final encontrado, el valor de la función en ese punto, el número\n",
    "de iteraciones y la trayectoria completa.\n",
    "\n",
    "Breve teoría: conservar estos datos permite comparar la efectividad del método según la inicialización, y\n",
    "evaluar si el valor mínimo parece coincidir entre inicios (indicio de mínimo global) o difiere (múltiples mínimos\n",
    "locales)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c53dc",
   "metadata": {},
   "source": [
    "### 8) Impresión de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18da6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in resultados_grad:\n",
    "    print(\"Punto␣inicial:\", r[\"inicio\"])\n",
    "    print(\" M nimo␣encontrado:\", r[\"minimo\"])\n",
    "    print(\"Valor␣en␣el␣ m nimo:\", r[\"valor_minimo\"])\n",
    "    print(\"Iteraciones:\", r[\"iteraciones\"])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22866d2",
   "metadata": {},
   "source": [
    "Qué hace: muestra por consola un resumen legible de cada experimento (inicio, mínimo, valor y número de\n",
    "iteraciones).\n",
    "\n",
    "Breve teoría: revisar estos resúmenes ayuda a detectar convergencia prematura, divergencia o que el método\n",
    "quedó atrapado en un mínimo local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa98d02",
   "metadata": {},
   "source": [
    "### 9) Construcción de la malla y evaluación para la gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90603ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-10, 10, 200)\n",
    "y_vals = np.linspace(-10, 10, 200)\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "Z = f(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e8bba",
   "metadata": {},
   "source": [
    "Qué hace: crea una malla 2D en el rectángulo [−10,10]×[−10,10] y evalúa la función f en cada punto para\n",
    "obtener la matriz Z de valores.\n",
    "\n",
    "Breve teoría: las curvas de nivel ayudan a visualizar la geometría local de f: pozos, valles, crestas y cómo se\n",
    "desplazan las trayectorias iterativas sobre ese paisaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e767f72",
   "metadata": {},
   "source": [
    "### 10) Trazado de curvas de nivel y trayectorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.contour(X, Y, Z, levels=30, cmap='viridis')\n",
    "\n",
    "for r in resultados_grad:\n",
    "    T = r[\"trayectoria\"]\n",
    "    plt.plot(T[:,0], T[:,1], 'o-', label=f'Inicio {r[\"inicio\"]}')\n",
    "\n",
    "plt.title(\"Trayectorias del Método del Gradiente Descendente\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d313e4c",
   "metadata": {},
   "source": [
    "Qué hace: dibuja las curvas de nivel de f y superpone las trayectorias de cada ejecución del gradiente\n",
    "descendente. Cada punto de la trayectoria se marca y se une en orden con líneas.\n",
    "\n",
    "Breve teoría: la visualización muestra si las trayectorias se dirigen al mismo mínimo, si oscilan (posible paso\n",
    "demasiado grande) o si se estancan. También permite evaluar la eficiencia del método según la geometría\n",
    "local (curvaturas grandes o pequeñas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5ec23",
   "metadata": {},
   "source": [
    "# Método de Newton:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72bb35c",
   "metadata": {},
   "source": [
    "### 1) Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9f890",
   "metadata": {},
   "source": [
    "Qué hace: carga las librerías numpy (para cálculo matricial) y matplotlib.pyplot (para graficar las trayectorias).\n",
    "\n",
    "Teoría: el método de Newton requiere operaciones vectoriales y matriciales como la evaluación del\n",
    "gradiente y la Hessiana, por lo que el uso de numpy facilita la implementación eficiente y precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317ef15",
   "metadata": {},
   "source": [
    "###  2) Definición de la función objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return 1 / (2 + np.cos(x + y)) + ((x- y)**2 + (x + y)**2) / 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21188f3a",
   "metadata": {},
   "source": [
    "Qué hace: define la función escalar f(x,y) que se desea minimizar.\n",
    "\n",
    "Teoría: la función está compuesta por un término oscilatorio y otro cuadrático que garantiza coercividad, es decir, f(x,y) → ∞ cuando ∥(x,y)∥ → ∞.\n",
    "Esto asegura la existencia de al menos un mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c0aca",
   "metadata": {},
   "source": [
    "###  3) Cálculo del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x, y):\n",
    "    df_dx = np.sin(x + y) / (2 + np.cos(x + y))**2 + x / 5\n",
    "    df_dy = np.sin(x + y) / (2 + np.cos(x + y))**2 + y / 5\n",
    "    return np.array([df_dx, df_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e58352",
   "metadata": {},
   "source": [
    "Qué hace: calcula el gradiente ∇f(x,y) de forma analítica.\n",
    "\n",
    "Teoría: el gradiente proporciona la dirección de máximo incremento de f; en métodos de optimización como Newton, se usa junto a la Hessiana para\n",
    "determinar una dirección de búsqueda más informada que la del gradiente descendente simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82320b35",
   "metadata": {},
   "source": [
    "### 4) Definición de la Hessiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessiana_f(x, y):\n",
    "    num = np.sin(x + y)**2 + 2*np.cos(x + y) + 1\n",
    "    den = (2 + np.cos(x + y))**3\n",
    "    h = num / den  # término común\n",
    "    return np.array([\n",
    "        [h + 1/5, h],\n",
    "        [h, h + 1/5]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb17e0f",
   "metadata": {},
   "source": [
    "Qué hace: implementa la matriz Hessiana exacta de la función objetivo. Definamos  u = x + y y calculaamos un término común h = g''(u) para g(u) = 1/(2 + cos u) usando la expresión del código:\n",
    "\n",
    "h = (sin²(u) + 2·cos(u) + 1) / (2 + cos(u))³\n",
    "Con ese h, construye la matriz:\n",
    "\n",
    "H(x, y) = [[h + 1/5, h],\n",
    "           [h, h + 1/5]]\n",
    "donde 1/5 proviene de la parte cuadrática (x² + y²)/10 (equivalente a ((x − y)² + (x + y)²)/20).\n",
    "\n",
    "Teoría: si escribimos f(x, y) = g(x + y) + (x² + y²)/10, la Hessiana se descompone en:\n",
    "\n",
    "Curvatura del término oscilatorio g(x + y), que aporta h = g''(u) en la diagonal y también en los términos cruzados (fuera de la diagonal), por eso aparecen h en las cuatro entradas.\n",
    "Curvatura constante de (x² + y²)/10, que añade 1/5 a cada diagonal y 0 fuera de la diagonal.\n",
    "\n",
    "\n",
    "También sabemos que H es simétrica y depende solo de u = x + y.\n",
    "El denominador (2 + cos u) ∈ [1, 3], por lo que no hay división por cero; aun así, valores muy pequeños de h pueden producir pasos grandes.\n",
    "Cuando g''(u) > 0, H suele estar mejor condicionada y más cercana a definida positiva, lo que favorece pasos de Newton estables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07921c",
   "metadata": {},
   "source": [
    "### 5) Parámetros y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "max_iter = 100\n",
    "puntos_iniciales = [np.array([2, -10]), np.array([-50, 5]), np.array([26, -10])]\n",
    "\n",
    "resultados_newton = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9199b1",
   "metadata": {},
   "source": [
    "Qué hace: establece la tolerancia ε, el número máximo de iteraciones y los puntos de inicio para probar\n",
    "la robustez del método.\n",
    "\n",
    "Teoría: el método de Newton puede converger muy rápido si el punto inicial está\n",
    "cerca del mínimo, pero puede divergir si está lejos o si la Hessiana no es definida positiva. Por eso se suelen\n",
    "probar distintos puntos iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af27c92",
   "metadata": {},
   "source": [
    "### 6) Bucle principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3820be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x0 in puntos_iniciales:\n",
    "    x = x0.copy()\n",
    "    trayectoria = [x.copy()]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        g = grad_f(x[0], x[1])\n",
    "        H = hessiana_f(x[0], x[1])\n",
    "        delta = np.linalg.solve(H, g)   # Resuelve H * delta = grad\n",
    "        x_new = x - delta\n",
    "        trayectoria.append(x_new.copy())\n",
    "        \n",
    "        if np.linalg.norm(x_new - x) < eps:\n",
    "            break\n",
    "        x = x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b0a00",
   "metadata": {},
   "source": [
    "Qué hace: aplica el método de Newton en forma iterativa:\n",
    "x_{k+1} = x_k − H^{-1}(x_k) ∇f(x_k)\n",
    "usando la instrucción np.linalg.solve para resolver el sistema lineal en lugar de calcular explícitamente\n",
    "la inversa de H.\n",
    "\n",
    "Teoría: el método aprovecha la curvatura local para acelerar la convergencia: si H se\n",
    "aproxima bien a la curvatura real de f, el método converge en muy pocas iteraciones (orden cuadrático)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ae22c",
   "metadata": {},
   "source": [
    "### 7) Almacenamiento de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_newton.append({\n",
    "        \"inicio\": x0,\n",
    "        \"minimo\": x,\n",
    "        \"valor_minimo\": f(x[0], x[1]),\n",
    "        \"iteraciones\": i+1,\n",
    "        \"trayectoria\": np.array(trayectoria)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd9830",
   "metadata": {},
   "source": [
    "Qué hace: guarda para cada ejecución los valores relevantes: punto inicial, mínimo encontrado, valor de la\n",
    "función, iteraciones y trayectoria.\n",
    "\n",
    "Teoría: este almacenamiento permite comparar convergencias y analizar\n",
    "si el método alcanza el mismo punto para distintos inicios (indicador de mínimo global)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba0489",
   "metadata": {},
   "source": [
    "### 8) Impresión de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff291670",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in resultados_newton:\n",
    "    print(\"Punto inicial:\", r[\"inicio\"])\n",
    "    print(\"Mínimo encontrado:\", r[\"minimo\"])\n",
    "    print(\"Valor en el mínimo:\", r[\"valor_minimo\"])\n",
    "    print(\"Iteraciones:\", r[\"iteraciones\"])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd26102",
   "metadata": {},
   "source": [
    "Qué hace: muestra en consola la información obtenida de cada prueba.\n",
    "\n",
    "Teoría: la revisión manual de los valores finales y el número de iteraciones ayuda a identificar posibles divergencias o estancamientos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9812af8",
   "metadata": {},
   "source": [
    "### 9) Construcción de la malla para graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-10, 10, 200)\n",
    "y_vals = np.linspace(-10, 10, 200)\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "Z = f(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc90962",
   "metadata": {},
   "source": [
    "Qué hace: crea una malla de puntos en el plano y calcula el valor de la función f en cada punto.\n",
    "\n",
    "Teoría:\n",
    "esto permite representar la superficie como curvas de nivel, útiles para visualizar la dirección y forma de la\n",
    "convergencia del método."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babeac1d",
   "metadata": {},
   "source": [
    "### 10) Visualización de trayectorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.contour(X, Y, Z, levels=30, cmap='plasma')\n",
    "\n",
    "for r in resultados_newton:\n",
    "    T = r[\"trayectoria\"]\n",
    "    plt.plot(T[:,0], T[:,1], 'o-', label=f'Inicio {r[\"inicio\"]}')\n",
    "\n",
    "plt.title(\"Trayectorias del Método de Newton\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cee84",
   "metadata": {},
   "source": [
    "Qué hace: traza las curvas de nivel de f y superpone las trayectorias obtenidas desde distintos puntos iniciales.\n",
    "\n",
    "Teoría: visualizar las trayectorias permite comprobar la rapidez con que cada punto inicial converge\n",
    "al mínimo y observar si hay sensibilidad frente al punto de partida o presencia de mínimos locales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92636674",
   "metadata": {},
   "source": [
    "# Comparación entre los resultados de los códigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe038b3",
   "metadata": {},
   "source": [
    "Se importa la librería pandas, la cual permite manejar y visualizar datos en forma tabular mediante estructuras\n",
    "llamadas DataFrame. Es especialmente útil para resumir los resultados de los experimentos numéricos\n",
    "y compararlos de forma ordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6811b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc52f7",
   "metadata": {},
   "source": [
    "Aquí se crea una lista vacía llamada 'comparacion', donde posteriormente se almacenarán los datos de interés\n",
    "(como los puntos iniciales, número de iteraciones y mínimos obtenidos) para ambos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4582a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, n in zip(resultados_grad, resultados_newton):\n",
    "    comparacion.append({\n",
    "        \"Inicio\": str(g[\"inicio\"]),\n",
    "        \"Iteraciones Gradiente\": g[\"iteraciones\"],\n",
    "        \"Iteraciones Newton\": n[\"iteraciones\"],\n",
    "        \"Mínimo Gradiente\": np.round(g[\"minimo\"], 4),\n",
    "        \"Mínimo Newton\": np.round(n[\"minimo\"], 4)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e55f7a",
   "metadata": {},
   "source": [
    "Este ciclo recorre simultáneamente las listas resultados_grad y resultados_newton, que contienen la información generada por cada método. Con zip(), se emparejan los resultados correspondientes a un mismo\n",
    "punto inicial. En cada iteración se agrega un diccionario a la lista 'comparacion' con los siguientes datos:\n",
    "\n",
    "• 'Inicio': el punto de partida desde el cual se aplicó cada método.\n",
    "\n",
    "• 'Iteraciones Gradiente' y 'Iteraciones Newton': el número de pasos que necesitó cada algoritmo\n",
    "para converger.\n",
    "\n",
    "• 'Mínimo Gradiente' y 'Mínimo Newton': las coordenadas del punto mínimo hallado por cada método,\n",
    "redondeadas a cuatro cifras decimales mediante np.round().\n",
    "\n",
    "Este proceso permite comparar la eficiencia y la precisión de ambos algoritmos para los mismos casos iniciales.\n",
    "Los datos recopilados se transforman en un DataFrame llamado 'df', lo que facilita su visualización en forma de tabla.\n",
    "El comando print(df) muestra en pantalla la comparación final, donde se pueden observar las diferencias entre el número de iteraciones y los puntos óptimos obtenidos por cada método.\n",
    "\n",
    "En resumen, este bloque de código sirve para sintetizar y analizar los resultados experimentales de ambos\n",
    "algoritmos de optimización, proporcionando una forma clara de evaluar cuál de ellos converge más rápido y\n",
    "hacia qué punto lo hace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
